{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1a70e21",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(90deg, #2d7ff9 0%, #2ecc71 100%); padding: 32px 24px; border-radius: 18px; margin-bottom: 24px; box-shadow: 0 4px 24px #0001; display: flex; align-items: center; gap: 32px;\">\n",
    "<img src=\"mrbeastlogo.png\" alt=\"MrBeast\" style=\"width:110px; border-radius:50%; box-shadow:0 2px 12px #0002;\">\n",
    "<div>\n",
    "<h1 style=\"margin-bottom: 0; color: #fff; font-size: 2.5rem; font-weight: 800; letter-spacing: -1px;\">\n",
    "MR Beast YouTube Yorumları Üzerinde Metin Ön İşleme\n",
    "</h1>\n",
    "<p style=\"color:#f8f8f8; font-size:1.2rem; margin-top:8px;\">\n",
    "Bu projede, <b>MR Beast'in en çok izlenen YouTube videosuna ait 100.000'den fazla yorumu</b> kullanarak profesyonel bir <span style='color:#ffe066'><b>metin ön işleme (text preprocessing)</b></span> süreci uygulayacağız.\n",
    "</p>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "<div style=\"background:#fffbe6; color:#b37f00; padding:18px 18px; border-radius:12px; margin-bottom:18px; font-size:1.1rem; border-left:6px solid #ffe066;\">\n",
    "<b>Case Study:</b> Gerçek bir sosyal medya veri seti üzerinde, <b>ham metni</b> makine öğrenmesi ve doğal dil işleme projelerinde kullanılabilecek <b>temiz ve anlamlı</b> bir forma dönüştüreceğiz.\n",
    "</div>\n",
    "\n",
    "<div style=\"background:#e3f6fc; color:#1a4d6e; padding:16px 18px; border-radius:12px; margin-bottom:18px; font-size:1.05rem;\">\n",
    "<b>Bu projede neler öğreneceksiniz?</b>\n",
    "<ul style=\"margin-top:8px;\">\n",
    "<li>Gerçek bir YouTube yorum veri setinin profesyonelce incelenmesi</li>\n",
    "<li>Veri temizleme, eksik ve tekrarlı verilerin yönetimi</li>\n",
    "<li>Metin standartlaştırma, noktalama ve özel karakter temizliği</li>\n",
    "<li>Stopword temizliği, lemmatizasyon ve stemming uygulamaları</li>\n",
    "<li>Ön işleme adımlarının etkisinin karşılaştırılması</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div style=\"background:#f8f8f8; color:#333; padding:12px 18px; border-radius:10px; margin-bottom:18px; font-size:1.05rem; border-left:4px solid #2d7ff9;\">\n",
    "<b>İş Akışı:</b> <br>\n",
    "1. Gerekli kütüphanelerin kurulumu ve importu<br>\n",
    "2. Veri setinin indirilmesi ve yüklenmesi<br>\n",
    "3. Veri setinin ilk incelemesi<br>\n",
    "4. Eksik ve tekrarlı verilerin temizlenmesi<br>\n",
    "5. Metinlerin küçük harfe dönüştürülmesi<br>\n",
    "6. Noktalama ve özel karakter temizliği<br>\n",
    "7. Stopword temizliği<br>\n",
    "8. Lemmatizasyon ve stemming<br>\n",
    "9. Sonuçların karşılaştırılması\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de49aa",
   "metadata": {},
   "source": [
    "## 📦 <span style=\"color:#2d7ff9\"><b>Gerekli Kütüphanelerin Kurulumu ve İmportu</b></span>\n",
    "\n",
    "<span style=\"color:#e67e22\"><b>Neden?</b></span>  \n",
    "Doğal dil işleme projelerinde, veri okuma, düzenleme ve metin işleme işlemlerini hızlı ve güvenilir şekilde gerçekleştirmek için güçlü Python kütüphanelerine ihtiyaç vardır. Bu kütüphaneler, metin verisinin işlenmesi ve analizinde endüstri standardı araçlar sunar.\n",
    "\n",
    "<span style=\"color:#16a085\"><b>Ne Yapıyoruz?</b></span>\n",
    "- Gerekli kütüphaneleri kuruyoruz (pip ile)\n",
    "- Kullanacağımız kütüphaneleri import ediyoruz\n",
    "- NLTK veri setlerini indiriyoruz (stopwords, tokenizer, lemmatizer için)\n",
    "\n",
    "<span style=\"background:#eafaf1; color:#1e824c; padding:6px 12px; border-radius:8px; display:inline-block;\">\n",
    "<b>Not:</b> Eğer kütüphaneler zaten kuruluysa, pip komutları tekrar çalıştırılsa da sorun olmaz.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d55dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Cemal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Cemal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Cemal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gerekli kütüphanelerin kurulumu (pip ile)\n",
    "!pip install kagglehub pandas numpy nltk spacy --quiet\n",
    "\n",
    "# NLTK veri setlerinin indirilmesi\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ceec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cemal\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Kütüphanelerin import edilmesi\n",
    "import pandas as pd  # Veri işleme\n",
    "import numpy as np   # Sayısal işlemler\n",
    "import re            # Regex ile metin temizliği\n",
    "import nltk          # Doğal dil işleme\n",
    "import spacy         # Gelişmiş NLP işlemleri için (isteğe bağlı)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import kagglehub     # Kaggle veri seti indirme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7ce1ba",
   "metadata": {},
   "source": [
    "## ⬇️ <span style=\"color:#2d7ff9\"><b>Veri Setinin İndirilmesi ve Yüklenmesi</b></span>\n",
    "\n",
    "<span style=\"color:#e67e22\"><b>Neden?</b></span>  \n",
    "Gerçek dünyadan alınmış büyük ölçekli bir veri seti üzerinde çalışmak, metin ön işleme tekniklerinin pratikteki etkisini ve gerekliliğini anlamak için kritik öneme sahiptir. Ayrıca, sosyal medya verileri genellikle gürültülü ve karmaşık olduğundan, gerçekçi bir senaryo sunar.\n",
    "\n",
    "<span style=\"color:#16a085\"><b>Ne Yapıyoruz?</b></span>\n",
    "- KaggleHub ile MrBeast'in en çok izlenen videosuna ait 100.000 YouTube yorumunu indiriyoruz.\n",
    "- Dosya yolunu bulup pandas ile veri setini yüklüyoruz.\n",
    "\n",
    "<span style=\"background:#fffbe6; color:#b37f00; padding:6px 12px; border-radius:8px; display:inline-block;\">\n",
    "<b>Not:</b> Kaggle API anahtarınız yoksa, <a href=\"https://www.kaggle.com/docs/api\">Kaggle'dan nasıl alınır?</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2b69f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/kanchana1990/mr-beast-most-viewed-yt-video-100k-comments?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.21M/4.21M [00:01<00:00, 4.22MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Cemal\\.cache\\kagglehub\\datasets\\kanchana1990\\mr-beast-most-viewed-yt-video-100k-comments\\versions\\1\n",
      "Yüklenen dosya: C:\\Users\\Cemal\\.cache\\kagglehub\\datasets\\kanchana1990\\mr-beast-most-viewed-yt-video-100k-comments\\versions\\1\\mrbeast.csv\n",
      "Yüklenen dosya: C:\\Users\\Cemal\\.cache\\kagglehub\\datasets\\kanchana1990\\mr-beast-most-viewed-yt-video-100k-comments\\versions\\1\\mrbeast.csv\n"
     ]
    }
   ],
   "source": [
    "# KaggleHub ile veri setini indiriyoruz\n",
    "path = kagglehub.dataset_download(\"kanchana1990/mr-beast-most-viewed-yt-video-100k-comments\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Dosya adını bul ve pandas ile oku\n",
    "import os\n",
    "csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "if csv_files:\n",
    "    data_path = os.path.join(path, csv_files[0])\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Yüklenen dosya: {data_path}\")\n",
    "else:\n",
    "    print(\"CSV dosyası bulunamadı!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3955b6",
   "metadata": {},
   "source": [
    "## 🔍 <span style=\"color:#2ecc71\"><b>Veri Setinin İlk İncelemesi</b></span>\n",
    "\n",
    "<span style=\"color:#e67e22\"><b>Neden?</b></span>  \n",
    "Veri setinin yapısını, sütunlarını ve temel istatistiklerini analiz etmek, sonraki temizlik ve ön işleme adımlarının doğru ve etkili şekilde planlanabilmesi için gereklidir. Veri kalitesini ve işlenebilirliğini anlamak için ilk inceleme şarttır.\n",
    "\n",
    "<span style=\"color:#16a085\"><b>Ne Yapıyoruz?</b></span>\n",
    "- Veri setinin ilk satırlarını görüntülüyoruz.\n",
    "- Sütun isimlerini ve veri tiplerini inceliyoruz.\n",
    "- Eksik değer ve temel istatistikleri kontrol ediyoruz.\n",
    "\n",
    "<span style=\"background:#e3f6fc; color:#1a4d6e; padding:6px 12px; border-radius:8px; display:inline-block;\">\n",
    "<b>Veri setini tanımadan temizlik yapılmaz!</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ec93173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri setinin ilk 5 satırı:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Anonymized Author</th>\n",
       "      <th>Published At</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Reply Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like I said in the video, subscribe if you hav...</td>\n",
       "      <td>fdf4f229f2dbfdf46f6e0826223d04af346d2933042717...</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>996380</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Huge props to the set designers, everything wa...</td>\n",
       "      <td>d8cf09a5150af849f5ded80b42915e5f59fec302309ec3...</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>507774</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jimmy's videos have transformed into high-octa...</td>\n",
       "      <td>22c9835e967a0d7189d823bed038ed815c87ef94e12fc8...</td>\n",
       "      <td>2023-10-30T10:25:26Z</td>\n",
       "      <td>4156</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this man is honestly too good for this world, ...</td>\n",
       "      <td>4449e34d6ad4572bc4a72264bb92f163bb00f671fcbc21...</td>\n",
       "      <td>2023-10-05T17:20:21Z</td>\n",
       "      <td>3935</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mr beast never fails to make good content</td>\n",
       "      <td>4d98df0918c507df760bb8672d21aa92577c2f909dda67...</td>\n",
       "      <td>2023-10-17T11:25:11Z</td>\n",
       "      <td>1495</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  Like I said in the video, subscribe if you hav...   \n",
       "1  Huge props to the set designers, everything wa...   \n",
       "2  Jimmy's videos have transformed into high-octa...   \n",
       "3  this man is honestly too good for this world, ...   \n",
       "4          mr beast never fails to make good content   \n",
       "\n",
       "                                   Anonymized Author          Published At  \\\n",
       "0  fdf4f229f2dbfdf46f6e0826223d04af346d2933042717...  2021-11-24T21:02:45Z   \n",
       "1  d8cf09a5150af849f5ded80b42915e5f59fec302309ec3...  2021-11-24T22:07:54Z   \n",
       "2  22c9835e967a0d7189d823bed038ed815c87ef94e12fc8...  2023-10-30T10:25:26Z   \n",
       "3  4449e34d6ad4572bc4a72264bb92f163bb00f671fcbc21...  2023-10-05T17:20:21Z   \n",
       "4  4d98df0918c507df760bb8672d21aa92577c2f909dda67...  2023-10-17T11:25:11Z   \n",
       "\n",
       "    Likes  Reply Count  \n",
       "0  996380          501  \n",
       "1  507774          501  \n",
       "2    4156           30  \n",
       "3    3935           24  \n",
       "4    1495            7  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veri setinin ilk 5 satırı\n",
    "print(\"Veri setinin ilk 5 satırı:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d12585b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sütunlar ve veri tipleri:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Comment              object\n",
       "Anonymized Author    object\n",
       "Published At         object\n",
       "Likes                 int64\n",
       "Reply Count           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sütun isimleri ve veri tipleri\n",
    "print(\"Sütunlar ve veri tipleri:\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbf34058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri seti şekli: (100000, 5)\n",
      "Eksik değer sayısı:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Comment              0\n",
       "Anonymized Author    0\n",
       "Published At         0\n",
       "Likes                0\n",
       "Reply Count          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temel istatistikler\n",
    "print(\"Veri seti şekli:\", df.shape)\n",
    "print(\"Eksik değer sayısı:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e8d4d8",
   "metadata": {},
   "source": [
    "## 🧹 <span style=\"color:#e67e22\"><b>Eksik ve Tekrarlı Verilerin Temizlenmesi</b></span>\n",
    "\n",
    "<span style=\"color:#e67e22\"><b>Neden?</b></span>  \n",
    "Eksik veya tekrarlı veriler, analiz ve modelleme aşamalarında yanıltıcı ve hatalı sonuçlara yol açabilir. Temiz ve tutarlı bir veri seti, güvenilir ve doğru analizlerin temelini oluşturur.\n",
    "\n",
    "<span style=\"color:#16a085\"><b>Ne Yapıyoruz?</b></span>\n",
    "- Eksik (NaN) değer içeren satırları siliyoruz.\n",
    "- Tamamen aynı olan (tekrarlı) satırları kaldırıyoruz.\n",
    "- Temizlenmiş veri setinin boyutunu kontrol ediyoruz.\n",
    "\n",
    "<span style=\"background:#fffbe6; color:#b37f00; padding:6px 12px; border-radius:8px; display:inline-block;\">\n",
    "<b>Temiz veri = Güvenilir analiz!</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92a0d5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eksik değerli satır sayısı: 0\n"
     ]
    }
   ],
   "source": [
    "# Eksik değerlerin temizlenmesi\n",
    "print(f\"Eksik değerli satır sayısı: {df.isnull().any(axis=1).sum()}\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2645e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tekrarlı satır sayısı: 0\n"
     ]
    }
   ],
   "source": [
    "# Tekrarlı satırların temizlenmesi\n",
    "print(f\"Tekrarlı satır sayısı: {df.duplicated().sum()}\")\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbefcbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temizlenmiş veri seti şekli: (100000, 5)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temizlenmiş veri seti şekli: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb7eaa8",
   "metadata": {},
   "source": [
    "## 🔡 <span style=\"color:#2d7ff9\"><b>Metinlerin Küçük Harfe Dönüştürülmesi</b></span>\n",
    "\n",
    "<span style=\"color:#e67e22\"><b>Neden?</b></span>  \n",
    "Büyük/küçük harf farklılıkları, aynı kelimenin farklı olarak algılanmasına neden olur ve analizde gereksiz çeşitlilik oluşturur. Tüm metni küçük harfe dönüştürmek, kelime bazlı analizlerde tutarlılık sağlar.\n",
    "\n",
    "<span style=\"color:#16a085\"><b>Ne Yapıyoruz?</b></span>\n",
    "- Yorum metinlerinin tamamını küçük harfe dönüştürüyoruz.\n",
    "- Sütun adını otomatik tespit ediyoruz (örnek: 'comment').\n",
    "\n",
    "<span style=\"background:#e3f6fc; color:#1a4d6e; padding:6px 12px; border-radius:8px; display:inline-block;\">\n",
    "<b>\"Hello\" ve \"hello\" aynı kelimedir!</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3718030a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sütunlar: Index(['Comment', 'Anonymized Author', 'Published At', 'Likes', 'Reply Count'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Anonymized Author</th>\n",
       "      <th>Published At</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Reply Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like i said in the video, subscribe if you hav...</td>\n",
       "      <td>fdf4f229f2dbfdf46f6e0826223d04af346d2933042717...</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>996380</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>huge props to the set designers, everything wa...</td>\n",
       "      <td>d8cf09a5150af849f5ded80b42915e5f59fec302309ec3...</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>507774</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jimmy's videos have transformed into high-octa...</td>\n",
       "      <td>22c9835e967a0d7189d823bed038ed815c87ef94e12fc8...</td>\n",
       "      <td>2023-10-30T10:25:26Z</td>\n",
       "      <td>4156</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this man is honestly too good for this world, ...</td>\n",
       "      <td>4449e34d6ad4572bc4a72264bb92f163bb00f671fcbc21...</td>\n",
       "      <td>2023-10-05T17:20:21Z</td>\n",
       "      <td>3935</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mr beast never fails to make good content</td>\n",
       "      <td>4d98df0918c507df760bb8672d21aa92577c2f909dda67...</td>\n",
       "      <td>2023-10-17T11:25:11Z</td>\n",
       "      <td>1495</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  like i said in the video, subscribe if you hav...   \n",
       "1  huge props to the set designers, everything wa...   \n",
       "2  jimmy's videos have transformed into high-octa...   \n",
       "3  this man is honestly too good for this world, ...   \n",
       "4          mr beast never fails to make good content   \n",
       "\n",
       "                                   Anonymized Author          Published At  \\\n",
       "0  fdf4f229f2dbfdf46f6e0826223d04af346d2933042717...  2021-11-24T21:02:45Z   \n",
       "1  d8cf09a5150af849f5ded80b42915e5f59fec302309ec3...  2021-11-24T22:07:54Z   \n",
       "2  22c9835e967a0d7189d823bed038ed815c87ef94e12fc8...  2023-10-30T10:25:26Z   \n",
       "3  4449e34d6ad4572bc4a72264bb92f163bb00f671fcbc21...  2023-10-05T17:20:21Z   \n",
       "4  4d98df0918c507df760bb8672d21aa92577c2f909dda67...  2023-10-17T11:25:11Z   \n",
       "\n",
       "    Likes  Reply Count  \n",
       "0  996380          501  \n",
       "1  507774          501  \n",
       "2    4156           30  \n",
       "3    3935           24  \n",
       "4    1495            7  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yorum metinlerinin küçük harfe dönüştürülmesi\n",
    "# Yorumların bulunduğu sütun genellikle 'comment' veya benzeri olur, kontrol edelim:\n",
    "print(\"Sütunlar:\", df.columns)\n",
    "text_col = 'comment' if 'comment' in df.columns else df.columns[0]\n",
    "df[text_col] = df[text_col].astype(str).str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af62726",
   "metadata": {},
   "source": [
    "## ✂️ <span style=\"color:#e67e22\"><b>Noktalama İşaretlerinin ve Özel Karakterlerin Temizlenmesi</b></span>\n",
    "\n",
    "<span style=\"color:#e67e22\"><b>Neden?</b></span>  \n",
    "Noktalama işaretleri ve özel karakterler, çoğu NLP uygulamasında anlam taşımadığı için kaldırılır. Bu adım, kelime analizini ve modellemeyi sadeleştirir ve gereksiz gürültüyü azaltır.\n",
    "\n",
    "<span style=\"color:#16a085\"><b>Ne Yapıyoruz?</b></span>\n",
    "- Regex ile metinlerden noktalama işaretleri ve özel karakterleri temizliyoruz.\n",
    "- Sadece harf ve boşluklar kalacak şekilde düzenliyoruz.\n",
    "\n",
    "<span style=\"background:#fffbe6; color:#b37f00; padding:6px 12px; border-radius:8px; display:inline-block;\">\n",
    "<b>\"!@#\" gibi karakterler analizde gereksizdir.</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "960fe2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Anonymized Author</th>\n",
       "      <th>Published At</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Reply Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like i said in the video subscribe if you have...</td>\n",
       "      <td>fdf4f229f2dbfdf46f6e0826223d04af346d2933042717...</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>996380</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>huge props to the set designers everything was...</td>\n",
       "      <td>d8cf09a5150af849f5ded80b42915e5f59fec302309ec3...</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>507774</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jimmys videos have transformed into highoctane...</td>\n",
       "      <td>22c9835e967a0d7189d823bed038ed815c87ef94e12fc8...</td>\n",
       "      <td>2023-10-30T10:25:26Z</td>\n",
       "      <td>4156</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this man is honestly too good for this world i...</td>\n",
       "      <td>4449e34d6ad4572bc4a72264bb92f163bb00f671fcbc21...</td>\n",
       "      <td>2023-10-05T17:20:21Z</td>\n",
       "      <td>3935</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mr beast never fails to make good content</td>\n",
       "      <td>4d98df0918c507df760bb8672d21aa92577c2f909dda67...</td>\n",
       "      <td>2023-10-17T11:25:11Z</td>\n",
       "      <td>1495</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  like i said in the video subscribe if you have...   \n",
       "1  huge props to the set designers everything was...   \n",
       "2  jimmys videos have transformed into highoctane...   \n",
       "3  this man is honestly too good for this world i...   \n",
       "4          mr beast never fails to make good content   \n",
       "\n",
       "                                   Anonymized Author          Published At  \\\n",
       "0  fdf4f229f2dbfdf46f6e0826223d04af346d2933042717...  2021-11-24T21:02:45Z   \n",
       "1  d8cf09a5150af849f5ded80b42915e5f59fec302309ec3...  2021-11-24T22:07:54Z   \n",
       "2  22c9835e967a0d7189d823bed038ed815c87ef94e12fc8...  2023-10-30T10:25:26Z   \n",
       "3  4449e34d6ad4572bc4a72264bb92f163bb00f671fcbc21...  2023-10-05T17:20:21Z   \n",
       "4  4d98df0918c507df760bb8672d21aa92577c2f909dda67...  2023-10-17T11:25:11Z   \n",
       "\n",
       "    Likes  Reply Count  \n",
       "0  996380          501  \n",
       "1  507774          501  \n",
       "2    4156           30  \n",
       "3    3935           24  \n",
       "4    1495            7  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Noktalama işaretleri ve özel karakterlerin temizlenmesi\n",
    "# Sadece harf ve boşluklar kalsın\n",
    "df[text_col] = df[text_col].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d72d2e",
   "metadata": {},
   "source": [
    "## 🚫 <span style=\"color:#2ecc71\"><b>Stopword (Anlamsız Kelime) Temizliği</b></span>\n",
    "\n",
    "<span style=\"color:#e67e22\"><b>Neden?</b></span>  \n",
    "Stopword'ler (örn. the, is, and) cümleye anlam katmayan, çok sık geçen kelimelerdir. Bunların çıkarılması, metnin anlamını bozmadan analizde daha anlamlı ve verimli sonuçlar elde edilmesini sağlar.\n",
    "\n",
    "<span style=\"color:#16a085\"><b>Ne Yapıyoruz?</b></span>\n",
    "- NLTK ile İngilizce stopword listesini yüklüyoruz.\n",
    "- Yorumlardan bu kelimeleri çıkarıyoruz.\n",
    "- Tokenizasyon (kelimeye bölme) işlemiyle birlikte uyguluyoruz.\n",
    "\n",
    "<span style=\"background:#e3f6fc; color:#1a4d6e; padding:6px 12px; border-radius:8px; display:inline-block;\">\n",
    "<b>Stopword temizliği = Daha anlamlı analiz!</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c136ef80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Anonymized Author</th>\n",
       "      <th>Published At</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Reply Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like said video subscribe havent already could...</td>\n",
       "      <td>fdf4f229f2dbfdf46f6e0826223d04af346d2933042717...</td>\n",
       "      <td>2021-11-24T21:02:45Z</td>\n",
       "      <td>996380</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>huge props set designers everything spot</td>\n",
       "      <td>d8cf09a5150af849f5ded80b42915e5f59fec302309ec3...</td>\n",
       "      <td>2021-11-24T22:07:54Z</td>\n",
       "      <td>507774</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jimmys videos transformed highoctane actionpac...</td>\n",
       "      <td>22c9835e967a0d7189d823bed038ed815c87ef94e12fc8...</td>\n",
       "      <td>2023-10-30T10:25:26Z</td>\n",
       "      <td>4156</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>man honestly good world imagine putting much e...</td>\n",
       "      <td>4449e34d6ad4572bc4a72264bb92f163bb00f671fcbc21...</td>\n",
       "      <td>2023-10-05T17:20:21Z</td>\n",
       "      <td>3935</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mr beast never fails make good content</td>\n",
       "      <td>4d98df0918c507df760bb8672d21aa92577c2f909dda67...</td>\n",
       "      <td>2023-10-17T11:25:11Z</td>\n",
       "      <td>1495</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  like said video subscribe havent already could...   \n",
       "1           huge props set designers everything spot   \n",
       "2  jimmys videos transformed highoctane actionpac...   \n",
       "3  man honestly good world imagine putting much e...   \n",
       "4             mr beast never fails make good content   \n",
       "\n",
       "                                   Anonymized Author          Published At  \\\n",
       "0  fdf4f229f2dbfdf46f6e0826223d04af346d2933042717...  2021-11-24T21:02:45Z   \n",
       "1  d8cf09a5150af849f5ded80b42915e5f59fec302309ec3...  2021-11-24T22:07:54Z   \n",
       "2  22c9835e967a0d7189d823bed038ed815c87ef94e12fc8...  2023-10-30T10:25:26Z   \n",
       "3  4449e34d6ad4572bc4a72264bb92f163bb00f671fcbc21...  2023-10-05T17:20:21Z   \n",
       "4  4d98df0918c507df760bb8672d21aa92577c2f909dda67...  2023-10-17T11:25:11Z   \n",
       "\n",
       "    Likes  Reply Count  \n",
       "0  996380          501  \n",
       "1  507774          501  \n",
       "2    4156           30  \n",
       "3    3935           24  \n",
       "4    1495            7  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopword temizliği\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "df[text_col] = df[text_col].apply(remove_stopwords)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075bfdb4",
   "metadata": {},
   "source": [
    "## 🌱 <span style=\"color:#e67e22\"><b>Lemmatizasyon ve Stemming</b></span>\n",
    "\n",
    "<span style=\"color:#e67e22\"><b>Neden?</b></span>  \n",
    "Kelime köklerine indirgeme (lemmatizasyon ve stemming), aynı anlama gelen farklı kelime formlarını tekilleştirir. Bu sayede, metin analizinde daha doğru ve anlamlı sonuçlar elde edilir; modelin karmaşıklığı azalır.\n",
    "\n",
    "<span style=\"color:#16a085\"><b>Ne Yapıyoruz?</b></span>\n",
    "- Lemmatizasyon: Kelimeleri sözlükteki kök haline çeviriyoruz.\n",
    "- Stemming: Kelimeleri köküne indiriyoruz (daha kaba bir yöntem).\n",
    "- Her iki yöntemi de uygulayıp karşılaştırıyoruz.\n",
    "\n",
    "<span style=\"background:#fffbe6; color:#b37f00; padding:6px 12px; border-radius:8px; display:inline-block;\">\n",
    "<b>\"running\" → \"run\" (lemma), \"runn\" (stem)</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7086e56f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Comment_lemma</th>\n",
       "      <th>Comment_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>like said video subscribe havent already could...</td>\n",
       "      <td>like said video subscribe havent already could...</td>\n",
       "      <td>like said video subscrib havent alreadi could win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>huge props set designers everything spot</td>\n",
       "      <td>huge prop set designer everything spot</td>\n",
       "      <td>huge prop set design everyth spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jimmys videos transformed highoctane actionpac...</td>\n",
       "      <td>jimmy video transformed highoctane actionpacke...</td>\n",
       "      <td>jimmi video transform highoctan actionpack blo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>man honestly good world imagine putting much e...</td>\n",
       "      <td>man honestly good world imagine putting much e...</td>\n",
       "      <td>man honestli good world imagin put much effort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mr beast never fails make good content</td>\n",
       "      <td>mr beast never fails make good content</td>\n",
       "      <td>mr beast never fail make good content</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  like said video subscribe havent already could...   \n",
       "1           huge props set designers everything spot   \n",
       "2  jimmys videos transformed highoctane actionpac...   \n",
       "3  man honestly good world imagine putting much e...   \n",
       "4             mr beast never fails make good content   \n",
       "\n",
       "                                       Comment_lemma  \\\n",
       "0  like said video subscribe havent already could...   \n",
       "1             huge prop set designer everything spot   \n",
       "2  jimmy video transformed highoctane actionpacke...   \n",
       "3  man honestly good world imagine putting much e...   \n",
       "4             mr beast never fails make good content   \n",
       "\n",
       "                                        Comment_stem  \n",
       "0  like said video subscrib havent alreadi could win  \n",
       "1                  huge prop set design everyth spot  \n",
       "2  jimmi video transform highoctan actionpack blo...  \n",
       "3  man honestli good world imagin put much effort...  \n",
       "4              mr beast never fail make good content  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatizasyon ve stemming fonksiyonları\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    lemmatized = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized)\n",
    "\n",
    "def stem_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stemmed = [stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed)\n",
    "\n",
    "# Lemmatizasyon uygulanıyor\n",
    "df[text_col + '_lemma'] = df[text_col].apply(lemmatize_text)\n",
    "# Stemming uygulanıyor\n",
    "df[text_col + '_stem'] = df[text_col].apply(stem_text)\n",
    "df[[text_col, text_col + '_lemma', text_col + '_stem']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722938b",
   "metadata": {},
   "source": [
    "## 🆚 <span style=\"color:#2d7ff9\"><b>Sonuçların Karşılaştırılması</b></span>\n",
    "\n",
    "<span style=\"color:#e67e22\"><b>Neden?</b></span>  \n",
    "Ön işleme adımlarının metin üzerindeki etkisini gözlemlemek, hangi işlemin metni nasıl değiştirdiğini ve analiz sonuçlarını nasıl etkilediğini anlamak için gereklidir. Bu karşılaştırma, en uygun ön işleme stratejisini seçmek için önemlidir.\n",
    "\n",
    "<span style=\"color:#16a085\"><b>Ne Yapıyoruz?</b></span>\n",
    "- Orijinal, lemmatize ve stem edilmiş metinlerden örnekler gösteriyoruz.\n",
    "- Farklıları gözlemliyoruz.\n",
    "\n",
    "<span style=\"background:#e3f6fc; color:#1a4d6e; padding:6px 12px; border-radius:8px; display:inline-block;\">\n",
    "<b>Ön işleme = Daha güçlü NLP modelleri!</b>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b33af1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orijinal ve işlenmiş örnekler:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Comment_lemma</th>\n",
       "      <th>Comment_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75721</th>\n",
       "      <td>que grande ojal algn da llames para jugar sera...</td>\n",
       "      <td>que grande ojal algn da llames para jugar seru...</td>\n",
       "      <td>que grand ojal algn da llame para jugar sera u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80184</th>\n",
       "      <td>tr chi con mc tht l tuyt vi cm n brawl staars ...</td>\n",
       "      <td>tr chi con mc tht l tuyt vi cm n brawl staars ...</td>\n",
       "      <td>tr chi con mc tht l tuyt vi cm n brawl staar t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19864</th>\n",
       "      <td>actually get money</td>\n",
       "      <td>actually get money</td>\n",
       "      <td>actual get money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76699</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92991</th>\n",
       "      <td>production around mins vid proves mrbeast hand...</td>\n",
       "      <td>production around min vid prof mrbeast hand gr...</td>\n",
       "      <td>product around min vid prove mrbeast hand grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76434</th>\n",
       "      <td>better original squid game</td>\n",
       "      <td>better original squid game</td>\n",
       "      <td>better origin squid game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84004</th>\n",
       "      <td>hell years already</td>\n",
       "      <td>hell year already</td>\n",
       "      <td>hell year alreadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80917</th>\n",
       "      <td>una locura total</td>\n",
       "      <td>una locura total</td>\n",
       "      <td>una locura total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60767</th>\n",
       "      <td>imagine chris karl chandler talking strangers ...</td>\n",
       "      <td>imagine chris karl chandler talking stranger m...</td>\n",
       "      <td>imagin chri karl chandler talk stranger metro ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50074</th>\n",
       "      <td>amazing</td>\n",
       "      <td>amazing</td>\n",
       "      <td>amaz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Comment  \\\n",
       "75721  que grande ojal algn da llames para jugar sera...   \n",
       "80184  tr chi con mc tht l tuyt vi cm n brawl staars ...   \n",
       "19864                                 actually get money   \n",
       "76699                                                      \n",
       "92991  production around mins vid proves mrbeast hand...   \n",
       "76434                         better original squid game   \n",
       "84004                                 hell years already   \n",
       "80917                                   una locura total   \n",
       "60767  imagine chris karl chandler talking strangers ...   \n",
       "50074                                            amazing   \n",
       "\n",
       "                                           Comment_lemma  \\\n",
       "75721  que grande ojal algn da llames para jugar seru...   \n",
       "80184  tr chi con mc tht l tuyt vi cm n brawl staars ...   \n",
       "19864                                 actually get money   \n",
       "76699                                                      \n",
       "92991  production around min vid prof mrbeast hand gr...   \n",
       "76434                         better original squid game   \n",
       "84004                                  hell year already   \n",
       "80917                                   una locura total   \n",
       "60767  imagine chris karl chandler talking stranger m...   \n",
       "50074                                            amazing   \n",
       "\n",
       "                                            Comment_stem  \n",
       "75721  que grand ojal algn da llame para jugar sera u...  \n",
       "80184  tr chi con mc tht l tuyt vi cm n brawl staar t...  \n",
       "19864                                   actual get money  \n",
       "76699                                                     \n",
       "92991  product around min vid prove mrbeast hand grea...  \n",
       "76434                           better origin squid game  \n",
       "84004                                  hell year alreadi  \n",
       "80917                                   una locura total  \n",
       "60767  imagin chri karl chandler talk stranger metro ...  \n",
       "50074                                               amaz  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Orijinal ve ön işlenmiş metinlerin karşılaştırılması\n",
    "print(\"Orijinal ve işlenmiş örnekler:\")\n",
    "display(df[[text_col, text_col + '_lemma', text_col + '_stem']].sample(10, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663da0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Sistem belirtilen yolu bulamıyor: 'kagglehub/datasets/kanchana1990/mr-beast-most-viewed-yt-video-100k-comments'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Kaynak dosya yolunu bul\u001b[39;00m\n\u001b[32m     12\u001b[39m kaynak_dosya = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindirilen_klasor\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m f.endswith(\u001b[33m'\u001b[39m\u001b[33m.csv\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     15\u001b[39m         kaynak_dosya = os.path.join(indirilen_klasor, f)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] Sistem belirtilen yolu bulamıyor: 'kagglehub/datasets/kanchana1990/mr-beast-most-viewed-yt-video-100k-comments'"
     ]
    }
   ],
   "source": [
    "# KaggleHub ile indirilen dosyayı çalışma klasörüne kopyala (hata almamak için tam yol kullanılır)\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# KaggleHub ile indirilen klasörün yolu (örnek: path değişkeni ile alınan yol)\n",
    "indirilen_klasor = path if 'path' in globals() else 'kagglehub/datasets/kanchana1990/mr-beast-most-viewed-yt-video-100k-comments'\n",
    "\n",
    "# Hedef dosya adı\n",
    "hedef_dosya = 'mr-beast-most-viewed-yt-video-100k-comments.csv'\n",
    "\n",
    "# Kaynak dosya yolunu bul\n",
    "kaynak_dosya = None\n",
    "for f in os.listdir(indirilen_klasor):\n",
    "    if f.endswith('.csv'):\n",
    "        kaynak_dosya = os.path.join(indirilen_klasor, f)\n",
    "        break\n",
    "\n",
    "if kaynak_dosya and os.path.exists(kaynak_dosya):\n",
    "    shutil.copyfile(kaynak_dosya, hedef_dosya)\n",
    "    print(f\"{kaynak_dosya} dosyası {hedef_dosya} olarak çalışma klasörüne kopyalandı.\")\n",
    "else:\n",
    "    print('CSV dosyası bulunamadı veya yol hatalı!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
